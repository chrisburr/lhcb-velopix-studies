{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from functools import wraps\n",
    "import json\n",
    "from itertools import tee\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from joblib import delayed, Parallel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change the default settings for plotting\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "# Do some monkey patching to fix pandas/#15296\n",
    "if not hasattr(pd.read_msgpack, 'read_msgpack'):\n",
    "    @wraps(pd.read_msgpack)\n",
    "    def read_msgpack(*args, **kwargs):\n",
    "        df = read_msgpack.read_msgpack(*args, **kwargs)\n",
    "        df.columns = [c.decode('utf-8') for c in df.columns]\n",
    "        return df\n",
    "\n",
    "    read_msgpack.read_msgpack = pd.read_msgpack\n",
    "    pd.read_msgpack = read_msgpack\n",
    "# Helpful function\n",
    "def pairwise(iterable):\n",
    "    \"s -> (s0,s1), (s1,s2), (s2, s3), ...\"\n",
    "    a, b = tee(iterable)\n",
    "    next(b, None)\n",
    "    return zip(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scenarios = ['tip_x=0um_y=+1000um', 'Original_DB', 'tip_x=0um_y=-1000um']\n",
    "for scenario in glob('output/scenarios/*/particles.msg'):\n",
    "    scenarios.append(scenario[len('output/scenarios/'):-len('/particles.msg')])\n",
    "\n",
    "clusters, tracks, residuals, particles = [], [], [], []\n",
    "for scenario in scenarios:\n",
    "    df = pd.read_msgpack(f'output/scenarios/{scenario}/clusters.msg')\n",
    "    df['scenario'] = pd.Categorical([scenario]*len(df), categories=scenarios)\n",
    "    clusters.append(df)\n",
    "\n",
    "    df = pd.read_msgpack(f'output/scenarios/{scenario}/tracks.msg')\n",
    "    df['scenario'] = pd.Categorical([scenario]*len(df), categories=scenarios)\n",
    "    tracks.append(df)\n",
    "\n",
    "    df = pd.read_msgpack(f'output/scenarios/{scenario}/residuals.msg')\n",
    "    df['scenario'] = pd.Categorical([scenario]*len(df), categories=scenarios)\n",
    "    residuals.append(df)\n",
    "\n",
    "    df = pd.read_msgpack(f'output/scenarios/{scenario}/particles.msg')\n",
    "    df['scenario'] = pd.Categorical([scenario]*len(df), categories=scenarios)\n",
    "    particles.append(df)\n",
    "\n",
    "clusters = pd.concat(clusters)\n",
    "tracks = pd.concat(tracks)\n",
    "residuals = pd.concat(residuals)\n",
    "particles = pd.concat(particles)\n",
    "\n",
    "# residuals.eval('residual = sqrt(residual_x**2 + residual_y**2 + residual_z**2)', inplace=True)\n",
    "# residuals.eval('true_residual = sqrt(true_residual_x**2 + true_residual_y**2 + true_residual_z**2)', inplace=True)\n",
    "residuals['station'] = np.floor_divide(residuals.module, 2)\n",
    "\n",
    "tracks.track_type = list(map(lambda s: s.decode('utf-8'), tracks.track_type))\n",
    "tracks.track_type = tracks.track_type.astype('category')\n",
    "\n",
    "tracks.eval('p = sqrt(px**2 + py**2 + pz**2)', inplace=True)\n",
    "tracks.eval('pt = sqrt(px**2 + py**2)', inplace=True)\n",
    "tracks.eval('true_p = sqrt(true_px**2 + true_py**2 + true_pz**2)', inplace=True)\n",
    "tracks.eval('true_pt = sqrt(true_px**2 + true_py**2)', inplace=True)\n",
    "\n",
    "particles.eval('fd = sqrt('\n",
    "    '(vertex_x - true_dst_vertex_x)**2 + '\n",
    "    '(vertex_y - true_dst_vertex_y)**2 + '\n",
    "    '(vertex_z - true_dst_vertex_z)**2'\n",
    "')', inplace=True)\n",
    "\n",
    "particles.eval('true_fd = sqrt('\n",
    "    '(true_d0_vertex_x - true_dst_vertex_x)**2 + '\n",
    "    '(true_d0_vertex_y - true_dst_vertex_y)**2 + '\n",
    "    '(true_d0_vertex_z - true_dst_vertex_z)**2'\n",
    "')', inplace=True)\n",
    "D0_mass = 1864.84\n",
    "speed_of_light = 299792458\n",
    "particles.eval('D0_p = sqrt(D0_p_x**2 + D0_p_y**2 + D0_p_z**2)', inplace=True)\n",
    "particles.eval(f'D0_gamma = 1/sqrt(1 + D0_p**2/{D0_mass**2})', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sigma = {\n",
    "    0.5: 0.382924922548026,\n",
    "    1: 0.682689492137086,\n",
    "    2: 0.954499736103642,\n",
    "    3: 0.997300203936740\n",
    "}\n",
    "bins = np.linspace(-0.2, 0.2, 100)\n",
    "sns.set_palette(sns.color_palette('colorblind', len(scenarios)))\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "particles.scenario.cat.categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $x/y/z$ residuals\n",
    "\n",
    "Here the residual is plotted between:\n",
    " - The cluster position in the true geometry\n",
    " - The point of closest approach for the track reconstuced in the misaligned geometry\n",
    "\n",
    "As you might expect this only (appreciably) affects the residual in $x$ for rotations around $y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for scenario in scenarios:\n",
    "    residuals.query(f'scenario == \"{scenario}\"').residual_x.hist(bins=bins, normed=True, alpha=0.5, label=scenario)\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('residual_x [mm]')\n",
    "plt.xlim((bins[0], bins[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for scenario in scenarios:\n",
    "    residuals.query(f'scenario == \"{scenario}\"').residual_y.hist(bins=bins, normed=True, alpha=0.5, label=scenario)\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('residual_y [mm]')\n",
    "plt.xlim((bins[0], bins[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for scenario in scenarios:\n",
    "    residuals.query(f'scenario == \"{scenario}\"').residual_y.hist(bins=bins, normed=True, alpha=0.5, label=scenario)\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('residual_z [mm]')\n",
    "plt.xlim((bins[0], bins[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $x/y/z$ residuals as a function of VP station\n",
    "\n",
    "Here I plot the $x/y/z$ residuals (above) as a function of VP station. The coutour lines corrosponding to the median, $\\pm1\\sigma$ and $\\pm2\\sigma$ are shown, where the values are obtained by taking the percentiles of the residual distribution.\n",
    "\n",
    "I also plot the true residual, which is the residual between the true cluster location (using nominal geometry) and the track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "station_positions = {\n",
    "    0: -281.25, 1: -256.25, 2: -231.25, 3: -206.25, 4: -131.25, 5: -56.25, 6: -31.25,\n",
    "    7: -6.25, 8: 18.75, 9: 43.75, 10: 68.75, 11: 93.75, 12: 118.75, 13: 143.75,\n",
    "    14: 168.75, 15: 193.75, 16: 218.75, 17: 243.75, 18: 268.75, 19: 318.75,\n",
    "    20: 393.75, 21: 493.75, 22: 593.75, 23: 643.75, 24: 693.75, 25: 743.75\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_residual(var, vs_station=False):\n",
    "    for scenario, colour in zip(scenarios, sns.color_palette(n_colors=len(scenarios))):\n",
    "        data = residuals.query(f'scenario == \"{scenario}\"')\n",
    "        stations = sorted(data.station.unique())\n",
    "        ys = []\n",
    "        for station in stations:\n",
    "            if scenario == 'Original_DB' and var.startswith('true_residual'):\n",
    "                residual = data.query(f'station == {station}')[var[len('true_'):]]\n",
    "            else:\n",
    "                residual = data.query(f'station == {station}')[var]\n",
    "            ys.append([\n",
    "                residual.quantile(0.5+sigma[2]/2),\n",
    "                residual.quantile(0.5+sigma[1]/2),\n",
    "                residual.median(),\n",
    "                residual.quantile(0.5-sigma[1]/2),\n",
    "                residual.quantile(0.5-sigma[2]/2)\n",
    "            ])\n",
    "        if vs_station:\n",
    "            xs = stations\n",
    "        else:\n",
    "            xs = [station_positions[x] for x in stations]\n",
    "        for y, alpha in zip(zip(*ys), [0.25, 0.75, 1, 0.75, 0.25]): \n",
    "            plt.plot(xs, y, c=colour, alpha=alpha, label=(scenario if alpha == 1 else None))\n",
    "\n",
    "    plt.legend(loc='best')\n",
    "    if vs_station:\n",
    "        plt.xlim((0, 25))\n",
    "    else:\n",
    "        plt.xlim((station_positions[0], station_positions[25]))\n",
    "    plt.xlabel('VP station')\n",
    "    plt.ylabel(f'{var} [mm]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_residual('residual_x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_residual('true_residual_x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_residual('residual_y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_residual('true_residual_y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_residual('residual_z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_residual('true_residual_z')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Momentum resolution of all long tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for scenario in scenarios:\n",
    "    long_tracks = tracks.query(f'(scenario == \"{scenario}\") & (track_type == \"Long\")')\n",
    "    resolution = long_tracks.eval('(p-true_p)/true_p').dropna()\n",
    "    resolution.hist(bins=np.linspace(-0.05, 0.05, 100), label=scenario, alpha=0.5, normed=True)\n",
    "plt.legend(loc='best')\n",
    "plt.xlim((-0.05, 0.05))\n",
    "plt.xlabel('Long track momentum resolution [% true momentum]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for scenario, colour in zip(scenarios, sns.color_palette(n_colors=len(scenarios))):\n",
    "    long_tracks = tracks.query(f'(scenario == \"{scenario}\") & (track_type == \"Long\")')\n",
    "    # Use a variable binning to avoid issues with low stats\n",
    "    xs = np.concatenate([\n",
    "        np.linspace(1300, 13000, 11),\n",
    "        np.arange(15000, 31001, 2000),\n",
    "        np.arange(35000, 61000, 4000)\n",
    "    ])\n",
    "    ys = []\n",
    "    for p_low, p_high in pairwise(xs):\n",
    "        resolution = long_tracks.query(f'({p_low} <= true_p) & (true_p < {p_high})')\n",
    "        resolution = resolution.eval('(p-true_p)/true_p').dropna()\n",
    "        if len(resolution) < 50:\n",
    "            print(p_low, scenario, len(resolution))\n",
    "        ys.append([\n",
    "            resolution.quantile(0.5+sigma[1]/2),\n",
    "            resolution.median(),\n",
    "            resolution.quantile(0.5-sigma[1]/2)\n",
    "        ])\n",
    "\n",
    "    for y, alpha in zip(zip(*ys), [0.75, 1, 0.75]):\n",
    "        plt.plot(xs[:-1]+np.diff(xs), y, c=colour, alpha=alpha, label=(scenario if alpha == 1 else None))\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.xlim((xs[0], xs[-1]))\n",
    "plt.xlabel('Long track momentum resolution [% true momentum]')\n",
    "plt.ylabel('True track momentum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $D^0$ vertex fit quality\n",
    "\n",
    "Here $D^{*+} \\rightarrow \\left(D^0 \\rightarrow K^+ K^- \\right) \\pi^+$ candidates are reconstructed by:\n",
    " - Truth matching tracks (created with NoPIDsParticleMaker) to ensure that all hits on a final state track are assoiated with the same MCParticle\n",
    " - The mother of both kaons is then required to be the same MCParticle\n",
    " - The mother of the pion must be the same as the mother of the mother of the kaons\n",
    "\n",
    "The vertex is then fitted using `LoKi::VertexFitter` to build a $D^0$\n",
    "\n",
    "TODO:\n",
    " - Do I need to worry if the mother of the kaon MCParticles is something other than a $D^0$ (so $D^0 \\rightarrow X\n",
    "\\rightarrow K^+ K^-)$?\n",
    " - Likewise for the $D^{*+}$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for scenario in scenarios:\n",
    "    chi2 = particles.query(f'scenario == \"{scenario}\"').vertex_chi2\n",
    "    label = f'{scenario} ({len(chi2)})'\n",
    "    if scenario == 'Original_DB':\n",
    "        chi2.hist(bins=np.linspace(0, 5, 51), label=label, alpha=0.5, normed=True)\n",
    "    else:\n",
    "        chi2.hist(bins=np.linspace(0, 5, 51), label=label, normed=True, histtype='step', lw=2)\n",
    "    print(f'{sum(chi2 > 5)} ({sum(chi2 > 5)/len(chi2):.1%}) events clipped for {scenario}')\n",
    "    # Print sigma values for if this was one side of a normal distribution\n",
    "    print(f'   0.5σ = {chi2.quantile(sigma[0.5]/2):.3f}')\n",
    "    print(f'   1σ   = {chi2.quantile(sigma[1]/2):.3f}')\n",
    "    print(f'   2σ   = {chi2.quantile(sigma[2]/2):.3f}')\n",
    "plt.legend(loc='best')\n",
    "plt.xlim((0, 5))\n",
    "plt.xlabel('D$^0$ vertex $\\chi^2$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flight distance resolution\n",
    "\n",
    "The flight distance is taken to be the distance between the reconstructed $D^0$ vertex (above) and the true $D^{*+}$ origin vertex. I **do not** consider if the $D^{*+}$ is promptly produced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for scenario in scenarios:\n",
    "    true_fd = particles.query(f'(scenario == \"{scenario}\")').true_fd\n",
    "    label = f'{scenario} ({len(true_fd)})'\n",
    "    if scenario == 'Original_DB':\n",
    "        true_fd.hist(bins=np.linspace(0, 5, 21), label=label, alpha=0.5, normed=True)\n",
    "    else:\n",
    "        true_fd.hist(bins=np.linspace(0, 5, 21), label=label, normed=True, histtype='step', lw=2)\n",
    "plt.legend(loc='best')\n",
    "plt.xlim((0, 5))\n",
    "plt.xlabel('True flight distance [mm]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for scenario in scenarios:\n",
    "    reco_fd = particles.query(f'(scenario == \"{scenario}\")').fd\n",
    "    label = f'{scenario} ({len(reco_fd)})'\n",
    "    if scenario == 'Original_DB':\n",
    "        reco_fd.hist(bins=np.linspace(0, 5, 21), label=label, alpha=0.5, normed=True)\n",
    "    else:\n",
    "        reco_fd.hist(bins=np.linspace(0, 5, 21), label=label, normed=True, histtype='step', lw=2)\n",
    "plt.legend(loc='best')\n",
    "plt.xlim((0, 5))\n",
    "plt.xlabel('Flight distance [mm]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for scenario in scenarios:\n",
    "    _particles = particles.query(f'(scenario == \"{scenario}\")')\n",
    "    reco_fd = _particles.fd\n",
    "    true_fd = _particles.true_fd\n",
    "    res = true_fd - reco_fd\n",
    "    print(scenario, sum(res > 1))\n",
    "    print(f'  median = {res.median():.3f}')\n",
    "    print(f'    0.5σ = {res.quantile(0.5+sigma[0.5]/2)-res.quantile(0.5-sigma[0.5]/2):.3f}')\n",
    "    print(f'      1σ = {res.quantile(0.5+sigma[1]/2)-res.quantile(0.5-sigma[1]/2):.3f}')\n",
    "    label = f'{scenario} ({len(res)})'\n",
    "    if scenario == 'Original_DB':\n",
    "        res.hist(bins=np.linspace(-1, 1, 22), label=label, alpha=0.5, normed=True)\n",
    "    else:\n",
    "        res.hist(bins=np.linspace(-1, 1, 22), label=label, normed=True, histtype='step', lw=2)\n",
    "plt.legend(loc='best')\n",
    "plt.xlim((-1, 1))\n",
    "plt.xlabel('(True - Reconstructed) flight distance [mm]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D0 lifetime\n",
    "\n",
    "Using reconstructed momentum of the $D^0$ in all cases.\n",
    "\n",
    "$\\gamma = \\frac{1}{\\sqrt{1+\\frac{p}{m\\left(D^0\\right)}^2}}$\n",
    "\n",
    "$t_{\\text{proper}} = \\frac{\\text{FD}*\\gamma}{c}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "particles.eval(f'proper_time = (fd/1000 * D0_gamma) /{speed_of_light}', inplace=True)\n",
    "particles.eval(f'true_proper_time = (true_fd/1000 * D0_gamma) /{speed_of_light}', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for scenario in scenarios:\n",
    "    lt = particles.query(f'(scenario == \"{scenario}\")').proper_time\n",
    "    label = f'{scenario} ({lt.quantile(1 - 1/np.exp(1))*1e12:.3f}ps)'\n",
    "    if scenario == 'Original_DB':\n",
    "        lt.hist(bins=np.linspace(0, 3e-12, 21), label=label, alpha=0.5, normed=True)\n",
    "    else:\n",
    "        lt.hist(bins=np.linspace(0, 3e-12, 21), label=label, normed=True, histtype='step', lw=2)\n",
    "plt.legend(loc='best')\n",
    "plt.xlim((0, 3e-12))\n",
    "plt.xlabel('Proper lifetime [s]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for scenario in scenarios:\n",
    "    lt = particles.query(f'(scenario == \"{scenario}\")').true_proper_time\n",
    "    label = f'{scenario} ({lt.quantile(1 - 1/np.exp(1))*1e12:.3f}ps)'\n",
    "    if scenario == 'Original_DB':\n",
    "        lt.hist(bins=np.linspace(0, 3e-12, 21), label=label, alpha=0.5, normed=True)\n",
    "    else:\n",
    "        lt.hist(bins=np.linspace(0, 3e-12, 21), label=label, normed=True, histtype='step', lw=2)\n",
    "plt.legend(loc='best')\n",
    "plt.xlim((0, 3e-12))\n",
    "plt.xlabel('True proper lifetime [s]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for scenario in scenarios:\n",
    "    _particles = particles.query(f'(scenario == \"{scenario}\")')\n",
    "    res = _particles.true_proper_time - _particles.proper_time\n",
    "    print(scenario, sum(res > 1))\n",
    "    print(f'  median = {res.median():.3f}')\n",
    "    print(f'    0.5σ = {res.quantile(0.5+sigma[0.5]/2)-res.quantile(0.5-sigma[0.5]/2):.3f}')\n",
    "    print(f'      1σ = {res.quantile(0.5+sigma[1]/2)-res.quantile(0.5-sigma[1]/2):.3f}')\n",
    "    label = f'{scenario} ({len(res)})'\n",
    "    if scenario == 'Original_DB':\n",
    "        res.hist(bins=np.linspace(-3e-13, 3e-13, 22), label=label, alpha=0.5, normed=True)\n",
    "    else:\n",
    "        res.hist(bins=np.linspace(-3e-13, 3e-13, 22), label=label, normed=True, histtype='step', lw=2)\n",
    "plt.legend(loc='best')\n",
    "plt.xlim((-3e-13, 3e-13))\n",
    "plt.xlabel('(True - Reconstructed) proper lifetime [s]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:analysis-3.6]",
   "language": "python",
   "name": "conda-env-analysis-3.6-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
